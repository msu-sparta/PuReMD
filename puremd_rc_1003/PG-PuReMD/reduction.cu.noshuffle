
#include "reduction.h"
#include "vector.h"

CUDA_GLOBAL void k_reduction(const real *input, real *per_block_results, const size_t n)
{
  extern __shared__ real sdata[];
  unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
  real x = 0;

  if(i < n)
  {
    x = input[i];
  }
  sdata[threadIdx.x] = x;
  __syncthreads();

  for(int offset = blockDim.x / 2; offset > 0; offset >>= 1)
  {
    if(threadIdx.x < offset)
    {
      sdata[threadIdx.x] += sdata[threadIdx.x + offset];
    }

    __syncthreads();
  }

  if(threadIdx.x == 0)
  {
    per_block_results[blockIdx.x] = sdata[0];
  }
}

CUDA_GLOBAL void k_reduction_rvec (rvec *input, rvec *results, size_t n)
{
  extern __shared__ rvec svec_data[];
  unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
  rvec x;

  rvec_MakeZero (x);

  if(i < n)
  {
   rvec_Copy (x, input[i]);
  }

  rvec_Copy (svec_data[threadIdx.x], x);
  __syncthreads();

  for(int offset = blockDim.x / 2; offset > 0; offset >>= 1)
  {
    if(threadIdx.x < offset)
    {
     rvec_Add (svec_data[threadIdx.x], svec_data[threadIdx.x + offset]);
    }

    __syncthreads();
  }

  if(threadIdx.x == 0)
  {
   //rvec_Copy (results[blockIdx.x], svec_data[0]);
   rvec_Add (results[blockIdx.x], svec_data[0]);
  }
}

CUDA_GLOBAL void k_reduction_rvec2 (rvec2 *input, rvec2 *results, size_t n)
{
  extern __shared__ rvec2 svec2_data[];
  unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
  rvec2 x;

  x[0] = 0.0;
  x[1] = 0.0;

  if(i < n)
  {
  	x[0] += input[i][0];
  	x[1] += input[i][1];
  }

  svec2_data [threadIdx.x][0] = x[0];
  svec2_data [threadIdx.x][1] = x[1];
  __syncthreads();

  for(int offset = blockDim.x / 2; offset > 0; offset >>= 1)
  {
    if(threadIdx.x < offset)
    {
	  svec2_data [threadIdx.x][0] += svec2_data [threadIdx.x + offset][0];
	  svec2_data [threadIdx.x][1] += svec2_data [threadIdx.x + offset][1];
    }

    __syncthreads();
  }

  if(threadIdx.x == 0)
  {
   //rvec_Copy (results[blockIdx.x], svec_data[0]);
	results [blockIdx.x][0] += svec2_data [0][0];
	results [blockIdx.x][1] += svec2_data [0][1];
  }
}

CUDA_GLOBAL void k_dot (const real *a, const real *b, real *per_block_results, const size_t n )
{
  extern __shared__ real sdot[];
  unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
  real x = 0;

  if(i < n)
  {
    x = a[i] * b[i];
  }
  sdot[threadIdx.x] = x;
  __syncthreads();

  for(int offset = blockDim.x / 2; offset > 0; offset >>= 1)
  {
    if(threadIdx.x < offset)
    {
      sdot[threadIdx.x] += sdot[threadIdx.x + offset];
    }

    __syncthreads();
  }

  if(threadIdx.x == 0)
  {
      per_block_results[blockIdx.x] = sdot[0];
  }
}

CUDA_GLOBAL void k_norm (const real *input, real *per_block_results, const size_t n, int pass)
{
  extern __shared__ real snorm[];
  unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
  real x = 0;

  if(i < n)
     x = SQR (input[i]);

  snorm[threadIdx.x] = x;
  __syncthreads();

  for(int offset = blockDim.x / 2; offset > 0; offset >>= 1)
  {
    if(threadIdx.x < offset)
    {
      snorm[threadIdx.x] += snorm[threadIdx.x + offset];
    }

    __syncthreads();
  }

  if(threadIdx.x == 0)
      per_block_results[blockIdx.x] = snorm[0];
}

CUDA_GLOBAL void k_norm_rvec2 (const rvec2 *input, rvec2 *per_block_results, const size_t n, int pass)
{
  extern __shared__ rvec2 snorm2[];
  unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
  rvec2 x;
  x[0] = x[1] = 0;

  if(i < n) {
  		if (pass == INITIAL) {	
     		x[0] = SQR (input[i][0]);
     		x[1] = SQR (input[i][1]);
	  } else {
     		x[0] = input[i][0];
     		x[1] = input[i][1];
	  }
  }

  snorm2[threadIdx.x][0] = x[0];
  snorm2[threadIdx.x][1] = x[1];
  __syncthreads();

  for(int offset = blockDim.x / 2; offset > 0; offset >>= 1)
  {
    if(threadIdx.x < offset)
    {
      snorm2[threadIdx.x][0] += snorm2[threadIdx.x + offset][0];
      snorm2[threadIdx.x][1] += snorm2[threadIdx.x + offset][1];
    }

    __syncthreads();
  }

  if(threadIdx.x == 0) {
      per_block_results[blockIdx.x][0] = snorm2[0][0];
      per_block_results[blockIdx.x][1] = snorm2[0][1];
  }
}

CUDA_GLOBAL void k_dot_rvec2 (const rvec2 *a, rvec2 *b, rvec2 *res, const size_t n)
{
  extern __shared__ rvec2 sdot2[];
  unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
  rvec2 x;
  x[0] = x[1] = 0;

  if(i < n) {
     	x[0] = a[i][0] * b[i][0];
     	x[1] = a[i][1] * b[i][1];
  }

  sdot2[threadIdx.x][0] = x[0];
  sdot2[threadIdx.x][1] = x[1];
  __syncthreads();

  for(int offset = blockDim.x / 2; offset > 0; offset >>= 1)
  {
    if(threadIdx.x < offset)
    {
      sdot2[threadIdx.x][0] += sdot2[threadIdx.x + offset][0];
      sdot2[threadIdx.x][1] += sdot2[threadIdx.x + offset][1];
    }

    __syncthreads();
  }

  if(threadIdx.x == 0) {
      res[blockIdx.x][0] = sdot2[0][0];
      res[blockIdx.x][1] = sdot2[0][1];
  }
}

//////////////////////////////////////////////////
//vector functions
//////////////////////////////////////////////////

CUDA_GLOBAL void k_vector_sum( real* dest, real c, real* v, real d, real* y, int k )
{
   int i = blockIdx.x * blockDim.x + threadIdx.x;
   if ( i >= k) return;

   dest[i] = c * v[i] + d * y[i];
}


CUDA_GLOBAL void k_vector_mul( real* dest, real* v, real* y, int k )
{
   int i = blockIdx.x * blockDim.x + threadIdx.x;
   if ( i >= k) return;

   dest[i] = v[i] * y[i];
}

CUDA_GLOBAL void k_rvec2_mul( rvec2* dest, rvec2* v, rvec2* y, int k )
{
   int i = blockIdx.x * blockDim.x + threadIdx.x;
   if ( i >= k) return;

   dest[i][0] = v[i][0] * y[i][0];
   dest[i][1] = v[i][1] * y[i][1];
}

CUDA_GLOBAL void k_rvec2_pbetad (rvec2 *dest, rvec2 *a, 
											real beta0, real beta1, 
											rvec2 *b, int n)
{
   int i = blockIdx.x * blockDim.x + threadIdx.x;
   if ( i >= n) return;

   dest[i][0] = a[i][0] + beta0 * b[i][0];
   dest[i][1] = a[i][1] + beta1 * b[i][1];
}
